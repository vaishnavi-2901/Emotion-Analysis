{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1  2  3  4  5\n",
      "0    1  0  0  0  0  0\n",
      "1    1  0  0  0  0  0\n",
      "2    1  0  0  0  0  0\n",
      "3    1  0  0  0  0  0\n",
      "4    1  0  0  0  0  0\n",
      "5    1  0  0  0  0  0\n",
      "6    1  0  0  0  0  0\n",
      "7    1  0  0  0  0  0\n",
      "8    1  0  0  0  0  0\n",
      "9    1  0  0  0  0  0\n",
      "10   1  0  0  0  0  0\n",
      "11   1  0  0  0  0  0\n",
      "12   1  0  0  0  0  0\n",
      "13   1  0  0  0  0  0\n",
      "14   1  0  0  0  0  0\n",
      "15   1  0  0  0  0  0\n",
      "16   0  1  0  0  0  0\n",
      "17   0  1  0  0  0  0\n",
      "18   0  0  1  0  0  0\n",
      "19   0  0  1  0  0  0\n",
      "20   0  0  1  0  0  0\n",
      "21   0  0  1  0  0  0\n",
      "22   0  0  1  0  0  0\n",
      "23   0  0  1  0  0  0\n",
      "24   0  0  1  0  0  0\n",
      "25   0  0  1  0  0  0\n",
      "26   0  0  1  0  0  0\n",
      "27   0  0  1  0  0  0\n",
      "28   0  0  1  0  0  0\n",
      "29   0  0  1  0  0  0\n",
      "..  .. .. .. .. .. ..\n",
      "161  0  0  0  0  0  1\n",
      "162  0  0  0  0  0  1\n",
      "163  0  0  0  0  0  1\n",
      "164  0  0  0  0  0  1\n",
      "165  0  0  0  0  0  1\n",
      "166  0  0  0  0  0  1\n",
      "167  0  0  0  0  0  1\n",
      "168  0  0  0  0  0  1\n",
      "169  0  0  0  0  0  1\n",
      "170  0  0  0  0  0  1\n",
      "171  0  0  0  0  0  1\n",
      "172  0  0  0  0  0  1\n",
      "173  0  0  0  0  0  1\n",
      "174  0  0  0  0  0  1\n",
      "175  0  0  0  0  0  1\n",
      "176  0  0  0  0  0  1\n",
      "177  0  0  0  0  0  1\n",
      "178  0  0  0  0  0  1\n",
      "179  0  0  0  0  0  1\n",
      "180  0  0  0  0  0  1\n",
      "181  0  0  0  0  0  1\n",
      "182  0  0  0  0  0  1\n",
      "183  0  0  0  0  0  1\n",
      "184  0  0  0  0  0  1\n",
      "185  0  0  0  0  0  1\n",
      "186  0  0  0  0  0  1\n",
      "187  0  0  0  0  0  1\n",
      "188  0  0  0  0  0  1\n",
      "189  0  0  0  0  0  1\n",
      "190  0  0  0  0  0  1\n",
      "\n",
      "[191 rows x 6 columns]\n",
      "Height of the image:  25\n",
      "Width of the image:   45\n",
      "Total number of data: 191\n",
      "lenght of train data: 127\n",
      "lenght of test data:  64\n",
      "lenght of train data: 127\n",
      "lenght of test data:  64\n",
      "train_set_x_flatten: (127, 1125)\n",
      "test_set_x_flatten : (64, 1125)\n",
      "[[161 168 168 ... 154 145 149]\n",
      " [150  34  43 ...   4   4  35]\n",
      " [110   2   3 ... 166 152 146]\n",
      " ...\n",
      " [ 41  48  64 ... 246 243 246]\n",
      " [106   2   2 ... 118 119 120]\n",
      " [255 255 255 ... 177 255 255]]\n",
      "[[0.63137255 0.65882353 0.65882353 ... 0.60392157 0.56862745 0.58431373]\n",
      " [0.58823529 0.13333333 0.16862745 ... 0.01568627 0.01568627 0.1372549 ]\n",
      " [0.43137255 0.00784314 0.01176471 ... 0.65098039 0.59607843 0.57254902]\n",
      " ...\n",
      " [0.16078431 0.18823529 0.25098039 ... 0.96470588 0.95294118 0.96470588]\n",
      " [0.41568627 0.00784314 0.00784314 ... 0.4627451  0.46666667 0.47058824]\n",
      " [1.         1.         1.         ... 0.69411765 1.         1.        ]]\n",
      "learning starts.......\n",
      "[[0.25098039 0.21960784 0.19607843 ... 0.38039216 0.31372549 0.05098039]\n",
      " [0.58823529 0.56078431 0.48627451 ... 0.29411765 0.30588235 0.49803922]\n",
      " [0.4627451  0.49019608 0.4745098  ... 0.40392157 0.42745098 0.43921569]\n",
      " ...\n",
      " [0.58823529 0.43529412 0.43529412 ... 0.08627451 0.09019608 0.32941176]\n",
      " [0.4745098  0.51764706 0.51764706 ... 0.45490196 0.5254902  0.54901961]\n",
      " [1.         1.         1.         ... 0.44705882 0.4745098  0.40392157]]\n",
      "length of train set: 127\n",
      "length of test set: 64\n",
      "shape of train set: (127, 1125)\n",
      "shape of test set: (64, 1125)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 1125), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\students\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "training with learning rate: 0.2\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\students\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "losses after per 1000 iteration:  8.048857\n",
      "losses after per 1000 iteration:  0.024704563\n",
      "losses after per 1000 iteration:  0.018802823\n",
      "losses after per 1000 iteration:  0.016469285\n",
      "losses after per 1000 iteration:  0.015199337\n",
      "losses after per 1000 iteration:  0.014393882\n",
      "losses after per 1000 iteration:  0.013833426\n",
      "losses after per 1000 iteration:  0.013417778\n",
      "losses after per 1000 iteration:  0.013095402\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob,os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# reading images from the data folder\n",
    "# label, smile = 1, neutral = 0\n",
    "(img_width, img_height) = (45, 25)\n",
    "def load_images_from_folder(folder):\n",
    "    (images, lables, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(folder):\n",
    "        #print subdirs, dirs\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join(folder, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = id\n",
    "                img = cv2.imread(path, 0) # Reading each images in grayscale\n",
    "                img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "                images.append(img)\n",
    "                lables.append(int(lable))\n",
    "            id += 1\n",
    "        \n",
    "        return images, lables, names\n",
    "X,Y,classes = load_images_from_folder(\"C:\\\\Users\\\\hp\\\\Desktop\\\\project work\\\\Main code and project\\\\Data\\\\face_data/\")\n",
    "\n",
    "(X,Y) = [np.array(lis) for lis in [X, Y]]\n",
    "Y = pd.get_dummies(Y)\n",
    "print(Y)\n",
    "#converting labels to one-hot, Used Pandas for it. \n",
    "\n",
    "print (\"Height of the image:  \" + str(X.shape[1]))\n",
    "print (\"Width of the image:   \"  + str(X.shape[2]))\n",
    "print (\"Total number of data: \"+ str(len(X)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "print (\"lenght of train data: \"+str(len(X_train)))\n",
    "print (\"lenght of test data:  \"+str(len(X_test)))\n",
    "\n",
    "print (\"lenght of train data: \"+str(len(X_train)))\n",
    "print (\"lenght of test data:  \"+str(len(X_test)))\n",
    "\n",
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1)\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "print (\"train_set_x_flatten: \"+str(train_set_x_flatten.shape))\n",
    "print (\"test_set_x_flatten : \"+str(test_set_x_flatten.shape))\n",
    "\n",
    "print (train_set_x_flatten)\n",
    "\n",
    "\n",
    "#Normalizing data, conveting all pixel value in range between 0-1\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "print(train_set_x)\n",
    "print(\"learning starts.......\")\n",
    "print(test_set_x)\n",
    "print (\"length of train set: \" + str(len(train_set_x)))\n",
    "print (\"length of test set: \" + str(len(test_set_x)))\n",
    "print (\"shape of train set: \"+ str(train_set_x.shape))\n",
    "print (\"shape of test set: \"+ str(test_set_x.shape))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 1125])\n",
    "print(x)\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "W = tf.Variable(rand(1125,6), dtype=tf.float32, name=\"w1\")\n",
    "b = tf.Variable(rand(6),  dtype=tf.float32, name=\"bias\")\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"first_operation\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 6], name = \"final_output\")\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "learning_rate = 0.2\n",
    "print (\"training with learning rate: \" + str(learning_rate))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(15000):\n",
    "        trainStep,loss = sess.run([train_step, cross_entropy], feed_dict={x: train_set_x, y_: y_train})\n",
    "        if step%1000==0:\n",
    "            print (\"losses after per 1000 iteration: \",loss)\n",
    "\n",
    "    save_path = saver.save(sess,  \"C:\\\\Users\\\\hp\\\\Desktop\\\\project work\\\\Main code and project\\\\Data\\\\emotions\\\\model/\")\n",
    "\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"accuracy with learning rate: \" ,str(learning_rate), sess.run(accuracy, feed_dict={x:test_set_x , y_: y_test}))\n",
    "    \n",
    "# W = tf.Variable(tf.zeros([1125, 2]),dtype = tf.float32, name=\"w1\")\n",
    "# b = tf.Variable(tf.zeros([2]), dtype = tf.float32,name=\"bias\")\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,  \"C:\\\\Users\\\\hp\\\\Desktop\\\\project work\\\\Main code and project\\\\Data\\\\emotions\\\\model/\")\n",
    "    print(\"w1:\", sess.run(W))\n",
    "    print(\"****\")\n",
    "    print(\"hello\")\n",
    "    print(\"bias:\", sess.run(b))\n",
    "    img = cv2.imread(\"C:\\\\Users\\\\hp\\\\Desktop\\\\project work\\\\Main code and project\\\\Data\\\\face_data\\\\Sad\\\\4.tiff\", 0) # Reading each images in grayscale \n",
    "                                                                          # test_2 is a neutral face\n",
    "                                                                            # test_1 is smile face\n",
    "    img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "    image=[]\n",
    "    image.append(img)\n",
    "    image_test = np.array(image)\n",
    "    test_image_flatten = image_test.reshape(image_test.shape[0],-1)\n",
    "    test_image_normalized = test_image_flatten/255.\n",
    "    print (test_image_normalized.shape)\n",
    "    x_ = tf.cast(test_image_normalized, tf.float32)\n",
    "    y = tf.nn.softmax(tf.matmul(x_, W) + b)\n",
    "    print (sess.run(y))\n",
    "    indx = sess.run(tf.argmax(y,1))\n",
    "    if indx==1:\n",
    "        print (\"calm\")\n",
    "    elif indx==0:\n",
    "        print (\"angry\")\n",
    "    \n",
    "    elif indx==2:\n",
    "        print (\"fear\")\n",
    "    \n",
    "    elif indx==3:\n",
    "        print (\"Happy\")\n",
    "        \n",
    "    \n",
    "    elif indx==4:\n",
    "        print (\"neutral\")\n",
    "    \n",
    "    elif indx==5:\n",
    "        print (\"sad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
